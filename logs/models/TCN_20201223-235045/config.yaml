data:
  augment: {input_noise: 5.0, mode: both_flip, probability: 0.75}
  batch_size: 256
  data_format: vector1D
  data_home: /home/abhinavg/data/takktile/data-v3
  data_transform:
    max: !!python/tuple
    - [93.0, 148.0, 88.0, 143.0, 139.0, 121.0]
    - [1.0, 1.0]
    mean: !!python/tuple
    - [-102.01859694748542, -90.12050240815941, -67.13406510384506, -46.37732915870606,
      -42.4609282491991, -59.15995554167242]
    - [0.0, 0.0]
    min: !!python/tuple
    - [-501.0, -503.0, -494.0, -497.0, -482.0, -468.0]
    - [0.0, 0.0]
    output_mean_zero: true
    std: !!python/tuple
    - [123.03371862830437, 108.53749128028433, 94.53040189437786, 79.98805914070563,
      76.24794232956299, 97.57098405202592]
    - [1.0, 1.0]
    type: standard
  eval_data: false
  file_format: mat
  histogram: {create: false, save: false, slip_filter: 1}
  label_dimension: translation
  label_type: slip
  materials: [matt, felt]
  radial_slip: true
  series_len: 100
  shuffle: true
  slip_filter: 1
  slip_thresh: {angular_speed: 0.5, flow: 2.5, speed: 0.03}
  test_data_exclude: [wood, foam, mat_light, coupled, rotation, combined]
  test_dir: /val/
  test_material: true
  train_data_exclude: [wood, foam, mat_light, coupled, rotation]
  train_dir: /train/
  truncate_pressure: 0
  use_pressure_delta: false
net:
  activation: selu
  best_model_path: /home/abhinavg/catkin_ws/src/learning-slip-perception/logs/models/TCN_20201223-235045/best_model/
  dilations: [1, 2, 4, 8]
  kernel_size: 8
  model_dir: /home/abhinavg/catkin_ws/src/learning-slip-perception/logs/models/TCN_20201223-235045
  name: tcn_takktile
  nb_filters: 12
  nb_stacks: 1
  output_layers: [24, 24]
  padding: causal
  return_sequences: false
  save_last_model: true
  trained: true
  type: tcn
  use_best_model: false
  use_skip_connections: false
training: {balance_data: false, class_weights: false, dropout_rate: 0.2, epochs: 0,
  epochs_complete: 200, kernel_initializer: he_normal, log_scaler_dir: /home/abhinavg/catkin_ws/src/learning-slip-perception/logs/scalars/20201223-235045,
  lr: 0.002, opt: adam, regression: false, use_batch_norm: false, use_layer_norm: true,
  verbosity: 1}
