data:
  batch_size: 128
  data_home: /home/abhinavg/data/takktile/data-v3/
  data_transform:
    max: !!python/tuple
    - [44.0, 43.0, 78.0, 28.0, 56.0, 23.0]
    - [1.0, 1.0]
    mean: !!python/tuple
    - [-73.13245842452514, -64.40572231896097, -63.86377142674569, -50.74738405993897,
      -39.89116890585811, -59.22162403949071]
    - [0.0, 0.0]
    min: !!python/tuple
    - [-494.0, -449.0, -494.0, -457.0, -482.0, -468.0]
    - [0.0, 0.0]
    output_mean_zero: true
    std: !!python/tuple
    - [86.18602274252173, 69.56915899283159, 85.23661097583157, 70.93109546760203,
      69.44669383514946, 85.32525335166154]
    - [1.0, 1.0]
    type: standard
  eval_data: false
  format: mat
  histogram: {create: false, save: false, slip_filter: 1}
  label_dimension: x
  label_type: slip
  series_len: 100
  shuffle: true
  slip_filter: 1
  slip_thresh: {angular_speed: 0.5, flow: 2.5, speed: 0.1}
  test_data_exclude: [coupled, rotation]
  test_dir: /val/
  train_data_exclude: [coupled, rotation]
  train_dir: /train/
net:
  activation: selu
  dilations: [1, 2, 4, 8, 8, 16, 32]
  kernel_size: 8
  model_dir: /home/abhinavg/catkin_ws/src/learning-slip-perception/logs/models/TCN_20201014-171558
  name: tcn_takktile
  nb_filters: 24
  nb_stacks: 1
  output_layers: [24, 24]
  padding: causal
  return_sequences: false
  trained: true
  type: tcn
  use_skip_connections: true
training: {dropout_rate: 0.1, epochs: 100, epochs_complete: 100, kernel_initializer: he_normal,
  log_scaler_dir: /home/abhinavg/catkin_ws/src/learning-slip-perception/logs/scalars/20201014-171558,
  lr: 0.002, opt: adam, regression: false, use_batch_norm: false, use_layer_norm: false,
  verbosity: 1}
