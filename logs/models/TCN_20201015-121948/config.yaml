data:
  batch_size: 128
  data_home: /home/abhinavg/data/takktile/data-v3/
  data_transform:
    max: !!python/tuple
    - [44.0, 43.0, 78.0, 28.0, 56.0, 23.0]
    - [1.0, 1.0]
    mean: !!python/tuple
    - [-59.31987934178241, -63.240562321320034, -72.71578911824956, -54.6258244603021,
      -34.75302208315512, -53.84404475159264]
    - [0.0, 0.0]
    min: !!python/tuple
    - [-494.0, -449.0, -494.0, -457.0, -476.0, -468.0]
    - [0.0, 0.0]
    output_mean_zero: true
    std: !!python/tuple
    - [74.3511582780537, 73.86016817599115, 95.42577859322247, 72.52179728237336,
      55.262603798231616, 71.08484213338143]
    - [1.0, 1.0]
    type: standard
  eval_data: false
  format: mat
  histogram: {create: false, save: false, slip_filter: 1}
  label_dimension: x
  label_type: slip
  series_len: 100
  shuffle: true
  slip_filter: 1
  slip_thresh: {angular_speed: 0.5, flow: 2.5, speed: 0.1}
  test_data_exclude: [coupled, rotation, y]
  test_dir: /val/
  train_data_exclude: [coupled, rotation, y]
  train_dir: /train/
net:
  activation: selu
  dilations: [1, 2, 4, 8]
  kernel_size: 8
  model_dir: /home/abhinavg/catkin_ws/src/learning-slip-perception/logs/models/TCN_20201015-121948
  name: tcn_takktile
  nb_filters: 24
  nb_stacks: 1
  output_layers: [16, 8]
  padding: causal
  return_sequences: false
  trained: true
  type: tcn
  use_skip_connections: true
training: {dropout_rate: 0.2, epochs: 100, epochs_complete: 100, kernel_initializer: he_normal,
  log_scaler_dir: /home/abhinavg/catkin_ws/src/learning-slip-perception/logs/scalars/20201015-121948,
  lr: 0.001, opt: adam, regression: false, use_batch_norm: false, use_layer_norm: false,
  verbosity: 1}
